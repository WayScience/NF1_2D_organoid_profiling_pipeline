{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Process single cell profiles"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import pathlib\n",
                "import pprint\n",
                "import sys\n",
                "\n",
                "import pandas as pd\n",
                "from pycytominer import aggregate, annotate, feature_select, normalize\n",
                "from pycytominer.cyto_utils import infer_cp_features\n",
                "\n",
                "cwd = pathlib.Path.cwd()\n",
                "\n",
                "if (cwd / \".git\").is_dir():\n",
                "    root_dir = cwd\n",
                "else:\n",
                "    root_dir = None\n",
                "    for parent in cwd.parents:\n",
                "        if (parent / \".git\").is_dir():\n",
                "            root_dir = parent\n",
                "            break\n",
                "sys.path.append(str(root_dir / \"utils\"))\n",
                "from notebook_init_utils import init_notebook\n",
                "\n",
                "root_dir, in_notebook = init_notebook()\n",
                "\n",
                "try:\n",
                "    cfg = get_ipython().config\n",
                "    in_notebook = True\n",
                "except NameError:\n",
                "    in_notebook = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running in a notebook\n"
                    ]
                }
            ],
            "source": [
                "if not in_notebook:\n",
                "    print(\"Running as script\")\n",
                "    # set up arg parser\n",
                "    parser = argparse.ArgumentParser(description=\"Segment the nuclei of a tiff image\")\n",
                "\n",
                "    parser.add_argument(\n",
                "        \"--patient\",\n",
                "        type=str,\n",
                "        help=\"Patient ID\",\n",
                "    )\n",
                "\n",
                "    args = parser.parse_args()\n",
                "    patient = args.patient\n",
                "else:\n",
                "    print(\"Running in a notebook\")\n",
                "    patient = \"NF0014_T1\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set paths and variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# output path for single-cell profiles\n",
                "output_dir = pathlib.Path(f\"../../data/{patient}\")\n",
                "output_dir.mkdir(parents=True, exist_ok=True)\n",
                "# operations to perform for feature selection\n",
                "feature_select_ops = [\n",
                "    \"variance_threshold\",\n",
                "    \"correlation_threshold\",\n",
                "    \"blocklist\",\n",
                "    \"drop_na_columns\",\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set dictionary with plates to process"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "middle_slice_sc = pathlib.Path(\n",
                "    f\"../../data/{patient}/0.converted/middle_slice_sc.parquet\"\n",
                ").resolve()\n",
                "max_projected_sc_output = pathlib.Path(\n",
                "    f\"../../data/{patient}/0.converted/max_projected_sc.parquet\"\n",
                ").resolve()\n",
                "middle_slice_organoid_output = pathlib.Path(\n",
                "    f\"../../data/{patient}/0.converted/middle_slice_organoid.parquet\"\n",
                ").resolve()\n",
                "max_projected_organoid_output = pathlib.Path(\n",
                "    f\"../../data/{patient}/0.converted/max_projected_organoid.parquet\"\n",
                ").resolve()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{   'organoid_max_projected': {   'aggregated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/4.aggregated/max_projected_organoid.parquet'),\n",
                        "                                  'annotated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/1.annotated/max_projected_organoid.parquet'),\n",
                        "                                  'feature_selected_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/3.feature_selected/max_projected_organoid.parquet'),\n",
                        "                                  'input_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/0.converted/max_projected_organoid.parquet'),\n",
                        "                                  'normalized_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/2.normalized/max_projected_organoid.parquet')},\n",
                        "    'organoid_middle_slice': {   'aggregated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/4.aggregated/middle_slice_organoid.parquet'),\n",
                        "                                 'annotated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/1.annotated/middle_slice_organoid.parquet'),\n",
                        "                                 'feature_selected_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/3.feature_selected/middle_slice_organoid.parquet'),\n",
                        "                                 'input_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/0.converted/middle_slice_organoid.parquet'),\n",
                        "                                 'normalized_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/2.normalized/middle_slice_organoid.parquet')},\n",
                        "    'sc_max_projected': {   'aggregated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/4.aggregated/max_projected_sc.parquet'),\n",
                        "                            'annotated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/1.annotated/max_projected_sc.parquet'),\n",
                        "                            'feature_selected_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/3.feature_selected/max_projected_sc.parquet'),\n",
                        "                            'input_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/0.converted/max_projected_sc.parquet'),\n",
                        "                            'normalized_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/2.normalized/max_projected_sc.parquet')},\n",
                        "    'sc_middle_slice': {   'aggregated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/4.aggregated/middle_slice_sc.parquet'),\n",
                        "                           'annotated_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/1.annotated/middle_slice_sc.parquet'),\n",
                        "                           'feature_selected_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/3.feature_selected/middle_slice_sc.parquet'),\n",
                        "                           'input_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/0.converted/middle_slice_sc.parquet'),\n",
                        "                           'normalized_path': PosixPath('/home/lippincm/4TB_A/NF1_2D_organoid_profiling_pipeline/data/NF0014_T1/2.normalized/middle_slice_sc.parquet')}}\n"
                    ]
                }
            ],
            "source": [
                "# create plate info dictionary\n",
                "plate_info_dictionary = {\n",
                "    \"sc_middle_slice\": {\n",
                "        \"input_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/0.converted/middle_slice_sc.parquet\"\n",
                "        ).resolve(strict=True),\n",
                "        \"annotated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/1.annotated/middle_slice_sc.parquet\"\n",
                "        ).resolve(),\n",
                "        \"normalized_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/2.normalized/middle_slice_sc.parquet\"\n",
                "        ).resolve(),\n",
                "        \"feature_selected_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/3.feature_selected/middle_slice_sc.parquet\"\n",
                "        ).resolve(),\n",
                "        \"aggregated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/4.aggregated/middle_slice_sc.parquet\"\n",
                "        ).resolve(),\n",
                "    },\n",
                "    \"sc_max_projected\": {\n",
                "        \"input_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/0.converted/max_projected_sc.parquet\"\n",
                "        ).resolve(strict=True),\n",
                "        \"annotated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/1.annotated/max_projected_sc.parquet\"\n",
                "        ).resolve(),\n",
                "        \"normalized_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/2.normalized/max_projected_sc.parquet\"\n",
                "        ).resolve(),\n",
                "        \"feature_selected_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/3.feature_selected/max_projected_sc.parquet\"\n",
                "        ).resolve(),\n",
                "        \"aggregated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/4.aggregated/max_projected_sc.parquet\"\n",
                "        ).resolve(),\n",
                "    },\n",
                "    \"organoid_middle_slice\": {\n",
                "        \"input_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/0.converted/middle_slice_organoid.parquet\"\n",
                "        ).resolve(strict=True),\n",
                "        \"annotated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/1.annotated/middle_slice_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "        \"normalized_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/2.normalized/middle_slice_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "        \"feature_selected_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/3.feature_selected/middle_slice_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "        \"aggregated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/4.aggregated/middle_slice_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "    },\n",
                "    \"organoid_max_projected\": {\n",
                "        \"input_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/0.converted/max_projected_organoid.parquet\"\n",
                "        ).resolve(strict=True),\n",
                "        \"annotated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/1.annotated/max_projected_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "        \"normalized_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/2.normalized/max_projected_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "        \"feature_selected_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/3.feature_selected/max_projected_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "        \"aggregated_path\": pathlib.Path(\n",
                "            f\"../../data/{patient}/4.aggregated/max_projected_organoid.parquet\"\n",
                "        ).resolve(),\n",
                "    },\n",
                "}\n",
                "\n",
                "# view the dictionary to assess that all info is added correctly\n",
                "pprint.pprint(plate_info_dictionary, indent=4)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Process data with pycytominer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "drug_information_df = pd.read_csv(\n",
                "    pathlib.Path(f\"{root_dir}/4.preprocess_features/data/drugs/drug_information.csv\")\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Performing pycytominer pipeline for sc_middle_slice\n",
                        "Performing annotation...\n",
                        "Performing normalization...\n",
                        "Performing feature selection for...\n",
                        "Performing aggregation...\n",
                        "Aggregation has been performed for:\n",
                        "sc_middle_slice\n",
                        "Performing pycytominer pipeline for sc_max_projected\n",
                        "Performing annotation...\n",
                        "Performing normalization...\n",
                        "Performing feature selection for...\n",
                        "Performing aggregation...\n",
                        "Aggregation has been performed for:\n",
                        "sc_max_projected\n",
                        "Performing pycytominer pipeline for organoid_middle_slice\n",
                        "Performing annotation...\n",
                        "Performing normalization...\n",
                        "Performing feature selection for...\n",
                        "Performing aggregation...\n",
                        "Aggregation has been performed for:\n",
                        "organoid_middle_slice\n",
                        "Performing pycytominer pipeline for organoid_max_projected\n",
                        "Performing annotation...\n",
                        "Performing normalization...\n",
                        "Performing feature selection for...\n",
                        "Performing aggregation...\n",
                        "Aggregation has been performed for:\n",
                        "organoid_max_projected\n"
                    ]
                }
            ],
            "source": [
                "for plate, info in plate_info_dictionary.items():\n",
                "    print(f\"Performing pycytominer pipeline for {plate}\")\n",
                "    # make the parent directories for the output files\n",
                "    for key, value in info.items():\n",
                "        value.parent.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    profile_df = pd.read_parquet(info[\"input_path\"])\n",
                "    platemap_df = pd.read_csv(\n",
                "        pathlib.Path(f\"{root_dir}/data/{patient}/platemap/platemap.csv\")\n",
                "    )\n",
                "    platemap_df.rename(columns={\"well_position\": \"Metadata_Well\"}, inplace=True)\n",
                "    # Step 1: Annotation\n",
                "    print(\"Performing annotation...\")\n",
                "    platemap_df = platemap_df.merge(\n",
                "        drug_information_df, how=\"left\", left_on=\"Metadata_Well\", right_on=\"Treatment\"\n",
                "    )\n",
                "    annotate(\n",
                "        profiles=profile_df,\n",
                "        platemap=platemap_df,\n",
                "        join_on=[\"Metadata_Well\", \"Metadata_Well\"],\n",
                "        output_file=info[\"annotated_path\"],\n",
                "        output_type=\"parquet\",\n",
                "    )\n",
                "\n",
                "    # Load the annotated parquet file to fix metadata columns names\n",
                "    annotated_df = pd.read_parquet(info[\"annotated_path\"])\n",
                "\n",
                "    print(\"Performing normalization...\")\n",
                "    # Step 2: Normalization\n",
                "    # Find the cp features based on the mask name or image\n",
                "    if \"organoid\" in plate.lower():\n",
                "        compartments = [\"Organoid\"]\n",
                "    else:\n",
                "        compartments = [\"Cells\", \"Nuclei\", \"Cytoplasm\"]\n",
                "    cp_features = infer_cp_features(\n",
                "        population_df=annotated_df, compartments=compartments\n",
                "    )\n",
                "\n",
                "    # Find the metadata features\n",
                "    meta_features = infer_cp_features(\n",
                "        population_df=annotated_df, compartments=compartments, metadata=True\n",
                "    )\n",
                "\n",
                "    # Perform normalization\n",
                "    normalize(\n",
                "        profiles=annotated_df,\n",
                "        features=cp_features,\n",
                "        meta_features=meta_features,\n",
                "        method=\"standardize\",\n",
                "        output_file=info[\"normalized_path\"],\n",
                "        output_type=\"parquet\",\n",
                "    )\n",
                "\n",
                "    print(\"Performing feature selection for...\")\n",
                "\n",
                "    # Step 3: Feature selection\n",
                "    fs_df = feature_select(\n",
                "        profiles=str(info[\"normalized_path\"]),\n",
                "        operation=feature_select_ops,\n",
                "        na_cutoff=0,\n",
                "        features=cp_features,\n",
                "        output_file=str(info[\"feature_selected_path\"]),\n",
                "        output_type=\"parquet\",\n",
                "    )\n",
                "\n",
                "    cp_features = infer_cp_features(\n",
                "        population_df=pd.read_parquet(info[\"feature_selected_path\"]),\n",
                "        compartments=compartments,\n",
                "    )\n",
                "    fs_df = pd.read_parquet(info[\"feature_selected_path\"])\n",
                "    # Step 4: Aggregation\n",
                "    print(\"Performing aggregation...\")\n",
                "    aggregate(\n",
                "        population_df=fs_df,\n",
                "        strata=[\"Metadata_treatment\", \"Metadata_dose\"],\n",
                "        features=cp_features,\n",
                "        operation=\"median\",\n",
                "        output_file=str(info[\"aggregated_path\"]),\n",
                "        output_type=\"parquet\",\n",
                "    )\n",
                "    print(f\"Aggregation has been performed for:\\n{plate}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nf1_image_based_profiling_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
